{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiser_parametres(input,output):\n",
    "    W=np.random.randn(input,output)*0.01\n",
    "    b=np.zeros((1,output))\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#propagation \n",
    "def propagation(X,W,b):\n",
    "    Z=np.dot(X,W)+b\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erreur quadratique moyenne\n",
    "def erreur_quadratique(y_pred,y_true):\n",
    "    return np.mean(np.square(y_pred-y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erreur_sortie(y_true,y_pred):\n",
    "    return y_pred*(1-y_pred)*(y_true-y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retropropagation\n",
    "def retropropagation(X,y_true,y_pred):\n",
    "    delta_sortie=erreur_sortie(y_true,y_pred)\n",
    "    dW=np.dot(X.T,delta_sortie)\n",
    "    db=np.sum(delta_sortie,axis=0,keepdims=True)\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mise a jour parametres\n",
    "def update_parametres(W,b,dW,db,taux_appr):\n",
    "    W+=taux_appr*dW\n",
    "    b+=taux_appr*db\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrainement du modèle\n",
    "def train(X_train, y_train,input,output,epochs,taux_appr):\n",
    "    W,b=initialiser_parametres(input,output)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #propagation avant\n",
    "        Z=propagation(X_train,W,b)\n",
    "        #calcul erreur\n",
    "        loss=erreur_quadratique(Z,y_train)\n",
    "        if epoch % 100 ==0:\n",
    "            print(f\"-------Epoch{epoch+1}/{epochs}, Loss{loss}-------\")\n",
    "\n",
    "        #retropropagation\n",
    "        dW,db=retropropagation(X_train,y_train,Z)\n",
    "        #mise a jour des parametres\n",
    "        W,b=update_parametres(W,b,dW,db,taux_appr)\n",
    "\n",
    "\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "def predict(X,W,b):\n",
    "    Z=propagation(X,W,b)\n",
    "    return np.argmax(Z,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding les sorties avec le nombre des classes:\n",
    "def one_hot_encode(y, num_classes):\n",
    "    one_hot = np.zeros((y.size, num_classes))\n",
    "    one_hot[np.arange(y.size), y] = 1\n",
    "    return one_hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1000, 15)\n",
      "y_train shape: (1000,)\n",
      "\n",
      "Exemple d'X_train: [1 1 1 1 0 1 1 1 1 1 0 1 1 1 1]\n",
      "Classe correspondante (y_train): 8\n"
     ]
    }
   ],
   "source": [
    "#echantillon:\n",
    "#on a par exemple pour la classe 1: 3,6,9,12,15 sont activés\n",
    "#pour classe 2: 1,2,3,6,9,8,7,10,13,14,15 sont activés \n",
    "#pour classe 3: 1,2,3,6,7,8,9,12,13,14,15 sont activés\n",
    "#classe 4: 1,3,4,6,7,8,9,12,15\n",
    "#classe5: 1,2,3,4,5,8,9,12,13,14,15\n",
    "#classe 6 : 1,2,3,4,7,8,9,10,12,13,14,15\n",
    "#classe 7: 1,2,3,6,7,8,9,12,15\n",
    "#classe 8 : 1,2,3,4,6,7,8,9,10,12,13,14,15\n",
    "#classe9: 1,2,3,4,6,7,8,9,12,13,14,15\n",
    "import numpy as np\n",
    "\n",
    "activation_patterns = {\n",
    "    1: [3, 6, 9, 12, 15],\n",
    "    2: [1, 2, 3, 6, 7, 8, 9, 10, 13, 14, 15],\n",
    "    3: [1, 2, 3, 6, 7, 8, 9, 12, 13, 14, 15],\n",
    "    4: [1, 3, 4, 6, 7, 8, 9, 12, 15],\n",
    "    5: [1, 2, 3, 4, 5, 8, 9, 12, 13, 14, 15],\n",
    "    6: [1, 2, 3, 4, 7, 8, 9, 10, 12, 13, 14, 15],\n",
    "    7: [1, 2, 3, 6, 7, 8, 9, 12, 15],\n",
    "    8: [1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15],\n",
    "    9: [1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 14, 15],\n",
    "}\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "X_train = np.zeros((n_samples, 15), dtype=int)  #les pixels\n",
    "y_train = np.zeros(n_samples, dtype=int)    #les classes\n",
    "\n",
    "#generer donnés\n",
    "for i in range(n_samples):\n",
    "    label = np.random.randint(1, 10)\n",
    "    y_train[i] = label\n",
    "    \n",
    "    activation_indices = activation_patterns[label]\n",
    "    \n",
    "    X_train[i, np.array(activation_indices) - 1] = 1  # Soustraction de 1 pour l'indexation 0-basée\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\nExemple d'X_train:\", X_train[0])\n",
    "print(\"Classe correspondante (y_train):\", y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Epoch1/1000, Loss0.101816075056823-------\n",
      "-------Epoch101/1000, Loss0.1023256664119178-------\n",
      "-------Epoch201/1000, Loss0.10304073964111382-------\n",
      "-------Epoch301/1000, Loss0.10408061465832599-------\n",
      "-------Epoch401/1000, Loss0.10567027693390182-------\n",
      "-------Epoch501/1000, Loss0.10828994875271046-------\n",
      "-------Epoch601/1000, Loss0.11317962657442672-------\n",
      "-------Epoch701/1000, Loss0.12482765706291607-------\n",
      "-------Epoch801/1000, Loss0.18305044315357136-------\n",
      "-------Epoch901/1000, Lossnan-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anis\\AppData\\Local\\Temp\\ipykernel_9908\\884405974.py:3: RuntimeWarning: overflow encountered in square\n",
      "  return np.mean(np.square(y_pred-y_true))\n",
      "C:\\Users\\Anis\\AppData\\Local\\Temp\\ipykernel_9908\\3054478958.py:2: RuntimeWarning: overflow encountered in multiply\n",
      "  return y_pred*(1-y_pred)*(y_true-y_pred)\n"
     ]
    }
   ],
   "source": [
    "y_train_one_hot=one_hot_encode(y_train,10)\n",
    "#hyperparams\n",
    "\n",
    "input_size=15\n",
    "output_size=10\n",
    "epochs=1000\n",
    "taux_appr=0.000001\n",
    "#entrainement\n",
    "W,b=train(X_train,y_train_one_hot,input_size,output_size,epochs,taux_appr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagation floue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------Perceptron Floue --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boltzmann_distribution(scores, T):\n",
    "    \"\"\"\n",
    "    Calcule les probabilités selon la distribution de Boltzmann.\n",
    "    scores : Les scores bruts du réseau (énergies associées aux classes)\n",
    "    T : Température qui contrôle la stochastique de l'échantillonnage\n",
    "    \"\"\"\n",
    "    exp_scores = np.exp(-scores / T)\n",
    "    probabilities = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    return probabilities\n",
    "\n",
    "def boltzmann_sampling(probabilities):\n",
    "    \"\"\"\n",
    "    Echantillonne une classe en fonction des probabilités de Boltzmann.\n",
    "    \"\"\"\n",
    "    # Échantillonner à partir des probabilités\n",
    "    return np.array([np.random.choice(len(p), p=p) for p in probabilities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagation_floue(X, W, b, T):\n",
    "    \"\"\"\n",
    "    Propagation avant avec distribution de Boltzmann.\n",
    "    X : Entrée\n",
    "    W : Poids\n",
    "    b : Biais\n",
    "    T : Température pour la distribution de Boltzmann\n",
    "    \"\"\"\n",
    "    Z = np.dot(X, W) + b  # Calcul des sorties brutes\n",
    "    probabilities = boltzmann_distribution(Z, T)  # Calcul des probabilités selon Boltzmann\n",
    "    y_pred = boltzmann_sampling(probabilities)    # Echantillonner les classes en fonction des probabilités\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrainement du modèle\n",
    "def train_floue(X_train, y_train,input,output,epochs,taux_appr):\n",
    "    W,b=initialiser_parametres(input,output)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #propagation avant\n",
    "        Z=propagation_floue(X_train,W,b)\n",
    "        #calcul erreur\n",
    "        loss=erreur_quadratique(Z,y_train)\n",
    "        if epoch % 100 ==0:\n",
    "            print(f\"-------Epoch{epoch+1}/{epochs}, Loss{loss}-------\")\n",
    "\n",
    "        #retropropagation\n",
    "        dW,db=retropropagation(X_train,y_train,Z)\n",
    "        #mise a jour des parametres\n",
    "        W,b=update_parametres(W,b,dW,db,taux_appr)\n",
    "\n",
    "\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Epoch1/1000, Loss0.09936806225993473-------\n",
      "-------Epoch101/1000, Loss0.09938958276979061-------\n",
      "-------Epoch201/1000, Loss0.09943949622413671-------\n",
      "-------Epoch301/1000, Loss0.09952625046705191-------\n",
      "-------Epoch401/1000, Loss0.09966137342091771-------\n",
      "-------Epoch501/1000, Loss0.09986078226432317-------\n",
      "-------Epoch601/1000, Loss0.10014692224857565-------\n",
      "-------Epoch701/1000, Loss0.10055242939281007-------\n",
      "-------Epoch801/1000, Loss0.10112677963525114-------\n",
      "-------Epoch901/1000, Loss0.10194927994036072-------\n"
     ]
    }
   ],
   "source": [
    "y_train_one_hot=one_hot_encode(y_train,10)\n",
    "#hyperparams\n",
    "\n",
    "input_size=15\n",
    "output_size=10\n",
    "epochs=1000\n",
    "taux_appr=0.000001\n",
    "#entrainement\n",
    "W,b=train(X_train,y_train_one_hot,input_size,output_size,epochs,taux_appr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
